{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7 - Introduction to clustering\n",
    "\n",
    "In this notebook we will see some techniques for clustering.\n",
    "Here, we will see only k-means, in the next session we will keep working on clustering and we will see some other methods as well.\n",
    "\n",
    "The notebook is divided in two parts:\n",
    "- firstly, we will be generate some artificial data to look at how k-means works\n",
    "- then, we will move to a real dataset (not used in previous sessions) and we will apply k-means to that\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Index\n",
    "\n",
    "- [0. imports](#0.)\n",
    "- [1. introduction to k-means](#1.)\n",
    "    - [1.1 Using the make_blobs method from sklearn](#1.1)\n",
    "    - [1.2 Changing the distribution](#1.2)\n",
    "    - [1.3 Changing the variance](#1.3)\n",
    "    - [1.4 Changing the size and density](#1.4)\n",
    "- [2. KMeans on a real intrusion detection dataset](#2.)\n",
    "    - [2.1 Load and explore the dataset](#2.1)\n",
    "    - [2.2 Mapping attacks to categories](#2.2)\n",
    "    - [2.3 Using scatter plots to analyze feature distribution](#2.3)\n",
    "    - [2.4 Prepare data for clustering](#2.4)\n",
    "    - [2.5 Perform the actual clustering](#2.5)\n",
    "    - [2.6 Data exploration after clustering](#2.6)\n",
    "    - [2.7 Using t-SNE](#2.7)\n",
    "    - [2.8 Evaluation](#2.8)\n",
    "    - [2.9 Using different values of K](#2.9)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.\n",
    "\n",
    "## Imports\n",
    "[Index](#Index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.\n",
    "## Introduction to KMeans\n",
    "\n",
    "[Index](#Index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example is inspired by [this one](https://scikit-learn.org/stable/auto_examples/cluster/plot_kmeans_assumptions.html#sphx-glr-auto-examples-cluster-plot-kmeans-assumptions-py) from the scikit-learn website."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1\n",
    "### Using the `make_blobs` method from sklearn\n",
    "[Index](#Index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to see how KMeans works in practice, we will start from some artificial 2D data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# definition of some variables which we will need in the next few cells\n",
    "\n",
    "# list of colors\n",
    "colors = ['tab:blue', 'tab:orange', 'tab:green', 'tab:red', 'tab:cyan', 'tab:purple', 'tab:gray', 'tab:olive']\n",
    "s = 20   # size of scatter plots\n",
    "a = 0.5  # transparency of scatter plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is the creation of three separate blobs of artificial data.\n",
    "They are pseudo-random, have a regular shape and are fairly far from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n_samples = 1500  # number of random points to generate\n",
    "random_state = 170  # random seed, for reproducibility\n",
    "\n",
    "# to generate the random blobs\n",
    "X, y = make_blobs(n_samples=n_samples, random_state=random_state)\n",
    "\n",
    "# plot them\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "ax.scatter(X[:, 0], X[:, 1], s=s, alpha=a, c='darkred')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now use KMeans to perform clustering.\n",
    "By looking at the data, we can see that it was generated in order to have three blobs.\n",
    "Let's start with 3 clusters, then.\n",
    "\n",
    "KMeans is provided in scikit-learn and it can trained in the same way as you would train a classifier (using `fit` and `predict`).\n",
    "However, since we perform the `predict` on the same data used for fitting it (as there is no test data), we can directly use the `fit_predict` method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = 3\n",
    "y_pred = KMeans(n_clusters=n_clusters, random_state=random_state).fit_predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now print the same blobs as above, but using different colours depending on the cluster that each point belongs to (according to the KMeans model we have just trained)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "ax.scatter(X[:, 0], X[:, 1], s=s, alpha=a, c=[colors[idx] for idx in y_pred])\n",
    "ax.set_title(\"n_clusters = %d\" % n_clusters)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything works as expected.\n",
    "\n",
    "However, if we use a different number of clusters, then things start to get a bit leass neat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = 2\n",
    "y_pred = KMeans(n_clusters=n_clusters, random_state=random_state).fit_predict(X)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "ax.scatter(X[:, 0], X[:, 1], s=s, alpha=a, c=[colors[idx] for idx in y_pred])\n",
    "ax.set_title(\"n_clusters = %d\" % n_clusters)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = 4\n",
    "y_pred = KMeans(n_clusters=n_clusters, random_state=random_state).fit_predict(X)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "ax.scatter(X[:, 0], X[:, 1], s=s, alpha=a, c=[colors[idx] for idx in y_pred])\n",
    "ax.set_title(\"n_clusters = %d\" % n_clusters)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = 5\n",
    "y_pred = KMeans(n_clusters=n_clusters, random_state=random_state).fit_predict(X)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "ax.scatter(X[:, 0], X[:, 1], s=s, alpha=a, c=[colors[idx] for idx in y_pred])\n",
    "ax.set_title(\"n_clusters = %d\" % n_clusters)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2\n",
    "### Changing the distribution\n",
    "[Index](#Index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also try with different distributions of data, and blobs with different shapes, densities, and sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformation = [[0.6, -0.6], [-0.4, 0.8]]\n",
    "X_transformed = np.dot(X, transformation)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "ax.scatter(X_transformed[:, 0], X_transformed[:, 1], s=s, alpha=a, c='darkred')\n",
    "ax.set_title(\"Original data\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_n_clusters = [[2,3], [4,5]]\n",
    "\n",
    "fig, ax = plt.subplots(2, 2, figsize=(12, 12))\n",
    "\n",
    "for idx1 in [0,1]:\n",
    "    for idx2 in [0,1]:\n",
    "        y_pred = KMeans(n_clusters=list_n_clusters[idx1][idx2], random_state=random_state).fit_predict(X_transformed)\n",
    "        ax[idx1][idx2].scatter(X_transformed[:, 0], X_transformed[:, 1], s=s, alpha=a, c=[colors[idx] for idx in y_pred])\n",
    "        ax[idx1][idx2].set_title(\"n_clusters = %d\" % list_n_clusters[idx1][idx2])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3\n",
    "### Changing the variance\n",
    "[Index](#Index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_var, y_var = make_blobs(n_samples=n_samples, cluster_std=[1.0, 2.5, 0.5], random_state=random_state)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "ax.scatter(X_var[:, 0], X_var[:, 1], s=s, alpha=a, c='darkred')\n",
    "ax.set_title(\"Original data\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "list_n_clusters = [[2,3], [4,5]]\n",
    "\n",
    "fig, ax = plt.subplots(2, 2, figsize=(12, 12))\n",
    "\n",
    "for idx1 in [0,1]:\n",
    "    for idx2 in [0,1]:\n",
    "        y_pred = KMeans(n_clusters=list_n_clusters[idx1][idx2], random_state=random_state).fit_predict(X_var)\n",
    "        ax[idx1][idx2].scatter(X_var[:, 0], X_var[:, 1], s=s, alpha=a, c=[colors[idx] for idx in y_pred])\n",
    "        ax[idx1][idx2].set_title(\"n_clusters = %d\" % list_n_clusters[idx1][idx2])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4\n",
    "### Changing the size and density\n",
    "[Index](#Index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_filtered = np.vstack((X[y == 0][:500], X[y == 1][:100], X[y == 2][:10]))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "ax.scatter(X_filtered[:, 0], X_filtered[:, 1], s=s, alpha=a, c='darkred')\n",
    "ax.set_title(\"Original data\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_n_clusters = [[2,3], [4,5]]\n",
    "\n",
    "fig, ax = plt.subplots(2, 2, figsize=(12, 12))\n",
    "\n",
    "for idx1 in [0,1]:\n",
    "    for idx2 in [0,1]:\n",
    "        y_pred = KMeans(n_clusters=list_n_clusters[idx1][idx2], random_state=random_state).fit_predict(X_filtered)\n",
    "        ax[idx1][idx2].scatter(X_filtered[:, 0], X_filtered[:, 1], s=s, alpha=a, c=[colors[idx] for idx in y_pred])\n",
    "        ax[idx1][idx2].set_title(\"n_clusters = %d\" % list_n_clusters[idx1][idx2])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that KMeans is not always capable of creating the correct clusters, and that is due to its algorithm.\n",
    "In the next session we will see some other clustering algorithms as well, to see how they compare on different distributions of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.\n",
    "## KMeans on a real intrusion detection dataset\n",
    "\n",
    "[Index](#Index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use a dataset which is an updated version of the KDD dataset we used in previous sessions.\n",
    "The original KDD dataset is useful for practicing and getting familiar with techniques, but it has some intrisic problems, related to how the data was collected and labeled.\n",
    "Go to [this webpage](https://www.unb.ca/cic/datasets/nsl.html) and have a look at the description of the new dataset to see how it addresses the problems of the KDD dataset (read [this paper](https://www.researchgate.net/publication/48446353_A_detailed_analysis_of_the_KDD_CUP_99_data_set), if you are intereseted in more details).\n",
    "\n",
    "---\n",
    "\n",
    "If you click on **[this link](http://205.174.165.80/CICDataset/NSL-KDD/Dataset/NSL-KDD.zip)** the download of the dataset should start.\n",
    "\n",
    "If the link above doesn't work, follw these instructions:\n",
    "- go to https://www.unb.ca/cic/datasets/nsl.html\n",
    "- scroll to the end of the page, there is a link to the actual download;\n",
    "- you will be redirected to another page asking for some information (there should be no check on the data you provide, so you can fill everything with *asd* if you want);\n",
    "- download the NSL-KDD.zip file\n",
    "\n",
    "---\n",
    "\n",
    "Regardless of the link you used for downloading the dataset, you should now have an archive named *NSL-KDD.zip*; extract it in the folder of the notebook\n",
    "\n",
    "You should now have a directory named NSL-KDD, containing several files. You have to focus on the following ones:\n",
    "- *index.html*: contains a brief description of the files, you should read it\n",
    "- *KDDTrain+.txt*: the file containing the training data\n",
    "- *KDDTest+.txt*: the file containing the test data\n",
    "\n",
    "In case you need it, there is also a reduced training set, stored in:\n",
    "- *KDDTrain+_20Percent.txt*: reduced training set\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1\n",
    "### Load and explore the dataset\n",
    "\n",
    "[Index](#Index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the filename for the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA_FILENAME = 'NSL-KDD/KDDTrain+.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN_DATA_FILENAME = 'NSL-KDD/KDDTrain+_20Percent.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the columns of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = [\n",
    "    'duration', 'protocol_type', 'service', 'flag', 'src_bytes', 'dst_bytes', 'land', 'wrong_fragment', \n",
    "    'urgent', 'hot', 'num_failed_logins', 'logged_in', 'num_compromised', 'root_shell', 'su_attempted', \n",
    "    'num_root', 'num_file_creations', 'num_shells', 'num_access_files', 'num_outbound_cmds', 'is_host_login', \n",
    "    'is_guest_login', 'count', 'srv_count', 'serror_rate', 'srv_serror_rate', 'rerror_rate', 'srv_rerror_rate', \n",
    "    'same_srv_rate', 'diff_srv_rate', 'srv_diff_host_rate', 'dst_host_count', 'dst_host_srv_count', \n",
    "    'dst_host_same_srv_rate', 'dst_host_diff_srv_rate', 'dst_host_same_src_port_rate', \n",
    "    'dst_host_srv_diff_host_rate', 'dst_host_serror_rate', 'dst_host_srv_serror_rate', 'dst_host_rerror_rate', \n",
    "    'dst_host_srv_rerror_rate', 'class', 'difficulty_level'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(TRAIN_DATA_FILENAME, names=headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Q: Display 5 random rows of the dataframe.</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Q: Display the first 5 rows of the dataframe.</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Q: Display the last 5 rows of the dataframe.</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Q: Show the columns of the dataframe</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Q: Print the number of rows of the dataframe</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Q: Print the number of columns of the dataframe</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Q: How many features are there in the original dataset?</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Q: Find the type of each feature (i.e. categorical, binary, numerical, etc.)</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Q: How many rows are there for each unique value of \"root_shell\"?</b>\n",
    "\n",
    "\\[It is a binary feature. if you though it was not a binary feature go back to the previous question and focus a bit more on that!\\]\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Q: How many rows are there for each unique value of \"logged_in\"?</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Q: How many rows are there for each unique value of \"class\"? Print and plot the distribution.</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2\n",
    "### Mapping attacks to categories\n",
    "\n",
    "[Index](#Index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As in the previous sessions, we will now map each value of the 'class' column to 1 of 5 possible categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_mapping = {\n",
    "    'normal': 'benign',\n",
    "    'back': 'dos',\n",
    "    'buffer_overflow': 'u2r',\n",
    "    'ftp_write': 'r2l',\n",
    "    'guess_passwd': 'r2l',\n",
    "    'imap': 'r2l',\n",
    "    'ipsweep': 'probe',\n",
    "    'land': 'dos',\n",
    "    'loadmodule': 'u2r',\n",
    "    'multihop': 'r2l',\n",
    "    'neptune': 'dos',\n",
    "    'nmap': 'probe',\n",
    "    'perl': 'u2r',\n",
    "    'phf': 'r2l',\n",
    "    'pod': 'dos',\n",
    "    'portsweep': 'probe',\n",
    "    'rootkit': 'u2r',\n",
    "    'satan': 'probe',\n",
    "    'smurf': 'dos',\n",
    "    'spy': 'r2l',\n",
    "    'teardrop': 'dos',\n",
    "    'warezclient': 'r2l',\n",
    "    'warezmaster': 'r2l',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['attack_type'] = train_df.apply(lambda r: category_mapping[r['class']], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Q: How many rows are there for each unique value of \"attack_type\"?</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Q: Plot the distribution of feature `duration`.</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first bin contains almost all the samples. \n",
    "\n",
    "We can address this issue in several ways:\n",
    "- using log scale\n",
    "- plotting separately values above and below a `duration` threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Q: Print the possible unique values of \"protocol_type\", and plot the ditribution.</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Q: Print the distribution of the \"src_bytes\" attribute.</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Q: Print the distribution of the \"src_bytes\" attribute, separately for each \"protocol_type\".</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Q: Print the distribution of the \"dst_bytes\" attribute, separately for each \"protocol_type\".</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3\n",
    "### Using scatter plots to analyze feature distribution\n",
    "\n",
    "[Index](#Index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By plotting with a scatter plot two attributes, we can look for correlations between them (and for rules taht might discriminate between different classes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = train_df['src_bytes'].values, train_df['dst_bytes'].values\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "most of the points are very close to 0.0 (be careful with the scale of the axis: it is 1e9, which means 10^9 !), let's focus on them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thres = 50000\n",
    "tmp_df = train_df[(train_df['src_bytes']<=thres)&(train_df['dst_bytes']<=thres)]\n",
    "x = tmp_df['src_bytes'].values\n",
    "y = tmp_df['dst_bytes'].values\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "ax.scatter(x, y, s=5, alpha=0.5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thres = 1000\n",
    "tmp_df = train_df[(train_df['src_bytes']<=thres)&(train_df['dst_bytes']<=thres)]\n",
    "x = tmp_df['src_bytes'].values\n",
    "y = tmp_df['dst_bytes'].values\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "ax.scatter(x, y, s=5, alpha=0.5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now do the same scatter plot but assigning a different color to each point, depending on the protocol_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = []\n",
    "for protocol in tmp_df['protocol_type'].values:\n",
    "    if protocol == 'tcp':\n",
    "        c.append('tab:green')\n",
    "    elif protocol == 'udp':\n",
    "        c.append('tab:orange')\n",
    "    elif protocol == 'icmp':\n",
    "        c.append('tab:blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thres = 1000\n",
    "tmp_df = train_df[(train_df['src_bytes']<=thres)&(train_df['dst_bytes']<=thres)]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "ax.scatter(tmp_df['src_bytes'].values, tmp_df['dst_bytes'].values, s=5, alpha=0.5, c=c)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, you could use the following plot for the scatter plot above, which is more convenient.\n",
    "\n",
    "You can also repeat the same plot removing one at a time the protocol types to better observe the distribution (or you could plot them in three different subplots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thres = 1000\n",
    "tmp_df = train_df[(train_df['src_bytes']<=thres)&(train_df['dst_bytes']<=thres)]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "tmp_df_icmp = tmp_df[tmp_df['protocol_type']=='icmp']\n",
    "ax.scatter(tmp_df_icmp['src_bytes'].values, tmp_df_icmp['dst_bytes'].values, s=5, alpha=0.5, c=colors[0], label='icmp')\n",
    "\n",
    "tmp_df_udp = tmp_df[tmp_df['protocol_type']=='udp']\n",
    "ax.scatter(tmp_df_udp['src_bytes'].values, tmp_df_udp['dst_bytes'].values, s=5, alpha=0.5, c=colors[1], label='udp')\n",
    "\n",
    "tmp_df_tcp = tmp_df[tmp_df['protocol_type']=='tcp']\n",
    "ax.scatter(tmp_df_tcp['src_bytes'].values, tmp_df_tcp['dst_bytes'].values, s=5, alpha=0.5, c=colors[2], label='tcp')\n",
    "\n",
    "ax.legend()\n",
    "ax.set_xlabel('src_bytes')\n",
    "ax.set_ylabel('dst_bytes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Q: Perform a similar analysis for the \"duration\" and the \"src_bytes\" attributes.</b> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Q: Plot the \"same_srv_rate\" against the \"diff_srv_rate\", and analyse it.</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case you know the true labels (benign or attack), so you could even perform the scatter plot separately for malicious samples and benign samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_benign = train_df[train_df['attack_type']=='benign']\n",
    "df_attack = train_df[train_df['attack_type']!='benign']\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "ax[0].scatter(df_benign['same_srv_rate'].values, df_benign['diff_srv_rate'].values, s=2, alpha=0.7, c='g', label='benign')\n",
    "ax[0].set_xlabel('same_srv_rate')\n",
    "ax[0].set_ylabel('diff_srv_rate')\n",
    "ax[0].legend()\n",
    "\n",
    "ax[1].scatter(df_attack['same_srv_rate'].values, df_attack['diff_srv_rate'].values, s=2, alpha=0.7, c='r', label='attack')\n",
    "ax[1].set_xlabel('same_srv_rate')\n",
    "ax[1].set_ylabel('diff_srv_rate')\n",
    "ax[1].legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the malicious samples are much more frequent than the benign samples, but actually that is not the case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Num benign samples = %d\" % len(df_benign))\n",
    "print(\"Num malicious samples = %d\" % len(df_attack))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This suggests that the benign samples are much more \"standard\" than the attacks, in the sense that they tend to frequently have similar values (at least for these two attributes we have observed here)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4\n",
    "### Prepare data for clustering\n",
    "\n",
    "[Index](#Index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to be able to perform clustering, we have to perform the usual preprocessing of the data:\n",
    "- one hot encoding\n",
    "- scaling\n",
    "\n",
    "If we don't do this we might encounter some problems (e.g. some features are ignored because the possible range of values is much lower than others)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = np.array(headers)\n",
    "\n",
    "nominal_idx = [1, 2, 3]\n",
    "binary_idx = [6, 11, 13, 14, 20, 21]\n",
    "numeric_idx = list(set(range(41)).difference(nominal_idx).difference(binary_idx))\n",
    "\n",
    "nominal_cols = col_names[nominal_idx].tolist()\n",
    "binary_cols = col_names[binary_idx].tolist()\n",
    "numeric_cols = col_names[numeric_idx].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Nominal cols:\\n\", nominal_cols, \"\\n\")\n",
    "print(\"Binary cols:\\n\", binary_cols, \"\\n\")\n",
    "print(\"numeric_cols:\\n\", numeric_cols, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Some of the clustering algorithms tend to be intractable on small machines as the dimensionality increases.\n",
    "Thus, in order to (hopefully) avoid problems on your machine, I remove here the 'service' column, which is a categorical one and increases a lot the dimensionality of the dataset</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.drop('service', axis=1)\n",
    "nominal_cols = [x for x in nominal_cols if x != 'service']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Q: Perform one hot encoding of the nominal cols</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = # TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Q: Perform scaling with the StandardScaler</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_scaler = # TODO\n",
    "train_df[numeric_cols] = # TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5\n",
    "### Perform the actual clustering\n",
    "\n",
    "[Index](#Index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While performing clustering, we do not want information about the label, since it is information that is missing in unseen data (it is the target label).\n",
    "So we will fit the clustering model on the dataframe after dropping such columns, as in:\n",
    "```\n",
    "    train_df.drop(['class', 'attack_type', 'difficulty_level'], axis=1)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- training the clustering algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = time.time()\n",
    "kmeans = KMeans(n_clusters=2, random_state=random_state).fit(\n",
    "    train_df.drop(['class', 'attack_type', 'difficulty_level'], axis=1)\n",
    ")\n",
    "print(\"Elapsed time = %.4f s\" % (time.time()-t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- you can print the centers of the clusters (which are, in this case, two 52-D points) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- you can print the labels for the elements in DF; these labels represent the ID of the clusters found with KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "kmeans.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- let's save those labels in a new column of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['cluster'] = kmeans.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6\n",
    "### Data exploration after clustering\n",
    "\n",
    "[Index](#Index)\n",
    "\n",
    "We can explore the data to visualize the clusters (plotting two features at a time) and understand how the KMeans algorithm worked.\n",
    "We can also plot the original classes (since in this case they were known to obsserve whether KMeans managed to separate them in different clusters)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 12))\n",
    "\n",
    "ax.scatter(train_df['same_srv_rate'].values, train_df['diff_srv_rate'].values, s=5, alpha=0.7, c=[colors[idx] for idx in train_df['cluster']])\n",
    "ax.set_xlabel('same_srv_rate')\n",
    "ax.set_ylabel('diff_srv_rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 12))\n",
    "\n",
    "ax.scatter(train_df['src_bytes'].values, train_df['dst_bytes'].values, s=5, alpha=0.7, c=[colors[idx] for idx in train_df['cluster']])\n",
    "ax.set_xlabel('src_bytes')\n",
    "ax.set_ylabel('dst_bytes')\n",
    "# ax.set_xlim(-0.02, 0.0)\n",
    "# ax.set_ylim(-0.02, 0.01)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.7\n",
    "### Using t-SNE\n",
    "\n",
    "[Index](#Index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem here is that we cannot plot more than two (possibly three) features. \n",
    "\n",
    "However, we might want to use [t-SNE](https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html#sklearn.manifold.TSNE) to better visualize the clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_embedded = TSNE(n_components=2, perplexity=20).fit_transform(train_df.drop(['class', 'attack_type', 'difficulty_level'], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_embedded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(18, 9))\n",
    "\n",
    "ax[0].set_title(\"KMeans clusters (k=2)\")\n",
    "ax[0].scatter(X_embedded[:,0], X_embedded[:,1], s=5, alpha=0.7, c=[colors[idx] for idx in train_df['cluster']])\n",
    "\n",
    "ax[1].set_title(\"Benign vs. malicious samples\")\n",
    "ax[1].scatter(X_embedded[:,0], X_embedded[:,1], s=5, alpha=0.7, c=['g' if attack=='benign' else 'r' for attack in train_df['attack_type']])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.8\n",
    "### Evaluation\n",
    "\n",
    "[Index](#Index)\n",
    "\n",
    "We will see the metrics for evaluating clustering in the next session, but here we can get an intuition of how well the clustering worked by looking at the true label (which in our case was known)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Q: In this case, we know the ground truth (i.e. the attack_type). Try to evaluate the accuracy of clustering by looking at the attack types of the entries of each cluster.</b>\n",
    "</div>\n",
    "\n",
    "e.g. after a perfect clustering, I'd have in each cluster only elements belonging to one attack_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.9\n",
    "### Using different values of K\n",
    "\n",
    "[Index](#Index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Q: Repeat the previous analysis using a different number of clusters.</b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
